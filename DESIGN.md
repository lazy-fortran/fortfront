# Character Type Inference Architecture (Issue #329)

## Problem Analysis

**Current Issue**: Character type inference has multiple limitations causing test failures and incorrect type defaults in the semantic analysis pipeline:

### Core Problems Identified

1. **Function Parameter Inference Failure** (test_issue_312)
   - Character parameters in functions default to `real(8)` instead of character
   - String concatenation operations (`//`) on parameters don't trigger character inference
   - Example: `function concat_hello(x); concat_hello = x // "!"` - parameter `x` should be character

2. **Semantic Preservation Issues** (test_semantic_preservation)
   - Scope preservation failing for character variables
   - Expression order not maintained in character operations
   - Declaration consolidation breaks with character types

3. **Type System Limitations**
   - Character literal inference works but doesn't propagate through expressions
   - Binary operator `//' only handles already-typed character operands
   - No backward propagation from character operations to untyped variables

## Root Cause Analysis

### Type Inference Flow Issues

1. **Unidirectional Inference**: Current system infers types forward (literals â†’ expressions) but lacks backward propagation (operations â†’ parameters)

2. **Default Type Assignment**: Untyped variables default to `real(8)` before context analysis

3. **Operation Context Loss**: String concatenation operator doesn't provide type hints to untyped operands

4. **Scope Chain Breaks**: Character type information lost when crossing scope boundaries

## Solution Architecture

### Phase 1: Enhanced Character Type Propagation

**Objective**: Implement backward type propagation from operations to parameters

**Key Changes**:
1. **Pre-Analysis Pass**: Scan for character operations before type defaulting
2. **Context-Aware Inference**: Use operation context to infer parameter types
3. **Deferred Defaulting**: Only apply `real(8)` default after exhausting inference

**Implementation Points**:
- Modify `infer_function` in `semantic_analyzer.f90`
- Add character operation detection before parameter type assignment
- Track character operations in function bodies during first pass

### Phase 2: Binary Operation Type Hints

**Objective**: Make `//' operator provide strong type hints to operands

**Key Changes**:
1. **Type Constraint Collection**: Gather constraints from operations before unification
2. **Bidirectional Unification**: Allow operations to constrain operand types
3. **Character Operation Registry**: Track all character operations for constraint solving

**Implementation Points**:
- Enhance `infer_binary_op` to collect type constraints
- Add constraint solver phase before type defaulting
- Implement character type propagation through expression trees

### Phase 3: Scope Preservation for Character Types

**Objective**: Maintain character type information across scopes

**Key Changes**:
1. **Scope Type Cache**: Preserve inferred types when entering/exiting scopes
2. **Character Type Persistence**: Ensure character types survive scope transitions
3. **Declaration Consolidation**: Special handling for character declarations

**Implementation Points**:
- Fix scope manager to preserve character type attributes
- Enhance declaration processing for character variables
- Maintain type consistency across scope boundaries

## Detailed Technical Specifications

### 1. Function Parameter Character Inference

```fortran
! Current behavior (WRONG):
function concat_hello(x)  ! x defaults to real(8)
    concat_hello = x // "!"  ! Type error or incorrect handling
end function

! Target behavior (CORRECT):
function concat_hello(x)  ! x inferred as character from usage
    character(len=:), allocatable :: x  ! or character(*)
    concat_hello = x // "!"
end function
```

**Algorithm**:
1. First pass: Collect all operations involving parameters
2. Identify character operations (`//`, character function calls)
3. Mark parameters used in character contexts
4. Apply character type before defaulting to real(8)

### 2. Character Operation Constraint Collection

**Data Structure**:
```fortran
type :: type_constraint_t
    integer :: var_index
    integer :: constraint_kind  ! MUST_BE_CHARACTER, etc.
    integer :: source_location  ! Where constraint originated
end type
```

**Process**:
1. During AST traversal, collect constraints
2. Solve constraints before type defaulting
3. Apply solved types to variables

### 3. Scope Preservation Enhancement

**Issue**: Character types lost during scope transitions

**Solution**:
- Add character type preservation to scope manager
- Implement proper type copying for character attributes
- Ensure allocatable info preserved across scopes

## Implementation Plan

### Step 1: Test Infrastructure (30 min)
- Create focused test cases for each failure mode
- Add regression tests for character inference
- Implement test helpers for type checking

### Step 2: Constraint Collection (1 hour)
- Add constraint data structures
- Implement constraint collection in semantic analyzer
- Create constraint solver for character types

### Step 3: Parameter Inference (1 hour)
- Modify function analysis to use constraints
- Implement backward propagation from operations
- Update parameter type assignment logic

### Step 4: Scope Preservation (45 min)
- Fix scope manager character handling
- Ensure type attributes preserved
- Update declaration consolidation

### Step 5: Integration Testing (45 min)
- Run full test suite
- Verify all 6 character tests pass
- Check for regressions

## Risk Assessment

### High Risk
- **Type System Regression**: Changes might affect non-character types
- **Mitigation**: Comprehensive regression testing, isolated changes

### Medium Risk
- **Performance Impact**: Additional analysis passes
- **Mitigation**: Optimize constraint collection, cache results

### Low Risk
- **Backward Compatibility**: Should be transparent to users
- **Mitigation**: Preserve existing API, internal changes only

## Success Criteria

1. **All 6 character-related semantic tests pass**
2. **No regression in existing tests**
3. **Function parameters correctly inferred as character**
4. **Scope preservation maintains character types**
5. **Expression order preserved for character operations**
6. **Declaration consolidation works with character types**

## Testing Strategy

### Unit Tests
- Character literal inference
- Character concatenation operations
- Function parameter inference
- Scope preservation

### Integration Tests
- Full program character handling
- Mixed type programs
- Complex character expressions

### Regression Tests
- All existing semantic tests
- Frontend integration tests
- Code generation verification

---

# Input Validation Module Architecture (Issue #262)

## Problem Analysis

**Current Issue**: Input validation logic is embedded within the `frontend.f90` module, creating tight coupling between validation concerns and the main transformation pipeline. This makes the validation logic:

- **Non-reusable**: Cannot be used independently for editor integration, build tools, or other applications
- **Hard to test**: Validation logic is tested indirectly through frontend transformation
- **Difficult to maintain**: Changes to validation affect the main frontend processing pipeline
- **Architecturally impure**: Violates single responsibility principle by mixing validation and transformation concerns

**Solution**: Extract validation logic into a dedicated `input_validation` module with clean separation of concerns and independent API.

## Module Architecture Design

### Input Validation Module (`src/input_validation.f90`)

**Purpose**: Dedicated module providing comprehensive input validation with enhanced error reporting, completely independent of frontend transformation logic.

**Dependencies**: 
- `lexer_core` only (for `token_t` type)
- No circular dependencies
- No dependency on `frontend` module

**Public API:**
```fortran
module input_validation
    use lexer_core, only: token_t
    implicit none
    private
    
    ! Primary validation interface
    public :: validate_basic_syntax
    
    ! Specific validation checks  
    public :: check_missing_then_statements
    public :: check_incomplete_statements
    public :: check_for_fortran_content
    public :: check_missing_end_constructs
    
    ! Utility functions
    public :: contains_invalid_patterns
    public :: has_only_meaningless_tokens
end module
```

### âœ… Current Validation Capabilities (Issue #256 Requirements)
- Enhanced error reporting with line/column information
- Source context with visual indicators pointing to errors  
- Helpful suggestions for fixing common syntax errors
- Elimination of silent fallback behavior
- Meaningful error output instead of empty programs
- Comprehensive syntax validation for all Fortran constructs

### ðŸŽ¯ New Capabilities (Issue #262 Goals)
1. **Standalone Usage**: Validation independent of frontend transformation
2. **Editor Integration**: Real-time syntax checking capabilities
3. **Build Tool Integration**: Pre-compilation validation for build systems
4. **Educational Applications**: Teaching tools with immediate syntax feedback
5. **Code Quality Tools**: Lint-style checking functionality

## Design Principles

- **Single Responsibility**: Input validation module focuses solely on validation concerns
- **Clean Dependencies**: No circular dependencies or coupling with frontend transformation
- **Reusability**: Module API designed for multiple use cases (CLI, editor, build tools)
- **Backward Compatibility**: Existing frontend functionality remains unchanged
- **Error Quality**: Maintain Issue #256 high-quality error reporting standards
- **Testability**: Independent module enables direct testing of validation logic

## Implementation Plan

### Phase 1: Module Creation
1. **Extract Validation Functions**: Move all validation logic from `frontend.f90` to new `src/input_validation.f90`
2. **Define Clean Interface**: Create public API with clear function signatures
3. **Implement Error Formatting**: Extract and enhance error message formatting functions
4. **Remove Dependencies**: Ensure module only depends on `lexer_core`

### Phase 2: Frontend Integration  
1. **Update Frontend**: Modify `frontend.f90` to use new `input_validation` module
2. **Preserve Behavior**: Ensure existing functionality works identically
3. **Maintain Error Quality**: Keep all Issue #256 error reporting improvements
4. **Test Integration**: Verify all existing tests continue to pass

### Phase 3: Enhanced Capabilities
1. **Standalone Validation**: Enable independent usage without frontend
2. **Enhanced Error Context**: Improve error messages with better source context
3. **Performance Optimization**: Optimize validation for repeated use
4. **Documentation**: Create comprehensive usage examples and API documentation

## Validation Function Specifications

### Primary Interface: `validate_basic_syntax`

```fortran
subroutine validate_basic_syntax(source, tokens, error_msg)
    character(len=*), intent(in) :: source
    type(token_t), intent(in) :: tokens(:)
    character(len=:), allocatable, intent(out) :: error_msg
```

**Purpose**: Main validation entry point that orchestrates all validation checks  
**Behavior**: Calls specialized validation functions in logical order  
**Error Format**: Enhanced Issue #256 format with line/column/context/suggestions

### Specialized Validation Functions

#### `check_missing_then_statements`
```fortran
subroutine check_missing_then_statements(tokens, source_lines, error_msg)
```
**Detects**: `if` statements missing required `then` keyword  
**Example Error**: "Missing 'then' statement at line 1, column 9"

#### `check_incomplete_statements`  
```fortran
subroutine check_incomplete_statements(tokens, source_lines, error_msg)
```
**Detects**: Dangling operators, incomplete expressions  
**Example Error**: "Incomplete expression: dangling '+' operator at line 1"

#### `check_for_fortran_content`
```fortran
subroutine check_for_fortran_content(tokens, error_msg)
```
**Detects**: Input without recognizable Fortran patterns  
**Multi-Phase Logic**: Comments â†’ Keywords â†’ Expressions â†’ Reject

#### `check_missing_end_constructs`
```fortran
subroutine check_missing_end_constructs(tokens, source_lines, error_msg)
```  
**Detects**: Program blocks without proper ending statements  
**Example Error**: "Missing 'end program' statement"

### Utility Functions

#### `contains_invalid_patterns`
```fortran
logical function contains_invalid_patterns(tokens)
```
**Returns**: True if tokens contain invalid syntax patterns

#### `has_only_meaningless_tokens`
```fortran
logical function has_only_meaningless_tokens(tokens)
```
**Returns**: True if input contains no meaningful Fortran content

## Integration with Existing System

### Frontend Module Changes
- **Import**: Add `use input_validation, only: validate_basic_syntax`
- **Replace**: Replace embedded validation logic with module calls
- **Preserve**: Maintain identical error reporting behavior
- **Cleanup**: Remove duplicated validation code

### Test Suite Compatibility
- **Existing Tests**: All current validation tests continue to pass
- **New Tests**: Additional tests for standalone module usage
- **Integration Tests**: Verify frontend still works with extracted module
- **Regression Testing**: Ensure Issue #256 requirements still met

### Performance Considerations
- **Module Loading**: Minimal overhead from additional module import
- **Function Calls**: Validation functions optimized for repeated use
- **Memory Usage**: No additional memory overhead compared to embedded logic
- **Compilation**: Clean module boundaries enable better compiler optimization

## Success Criteria

1. **âœ… Functional Requirements**:
   - All existing validation behavior preserved
   - Module can be used independently of frontend
   - Enhanced error reporting maintains Issue #256 quality standards

2. **âœ… Quality Requirements**:
   - Zero test regressions
   - Clean architectural separation
   - No circular dependencies
   - Comprehensive test coverage for standalone usage

3. **âœ… Documentation Requirements**:
   - Clear API documentation with examples
   - Integration guide for external usage
   - Architectural documentation updated

---

# Automatic Function Variable Declarations (Issue #320)

## Problem Analysis

**Current Issue**: Functions with undeclared variables generate incomplete standard Fortran code missing proper type declarations:

```fortran
! Input (lazy Fortran)
function twice(x) result(y)
    y = 2*x
end function

! Current Output (INCOMPLETE)
function twice(x) result(y)
    implicit none
    y = 2*x
end function twice

! Required Output (COMPLETE)
function twice(x) result(y)
    implicit none
    real(8), intent(in) :: x
    real(8) :: y
    y = 2*x
end function twice
```

**Root Challenge**: Type inference from function context alone is insufficient - requires complete program analysis or sophisticated type inference system.

**Design Philosophy**: Implement robust type inference leveraging Hindley-Milner type system and usage pattern analysis to automatically generate proper variable declarations.

## Solution Architecture

### Phase 1: Type Inference Engine Enhancement

**Objective**: Extend semantic analyzer to reliably infer types for undeclared function parameters and result variables

**Core Components**:

1. **Variable Discovery System**
   - Scan function scope for all undeclared variables
   - Distinguish between parameters, result variables, and local variables
   - Track variable usage patterns for type inference

2. **Context-Aware Type Inference**
   - Leverage existing Hindley-Milner type system
   - Analyze variable usage in expressions, assignments, and operations
   - Propagate type constraints bidirectionally through function body

3. **Intent Analysis Engine**
   - Determine appropriate intent attributes (in/out/inout) from usage patterns
   - Track read vs write operations for each parameter
   - Handle result variables separately (no intent required)

### Phase 2: Declaration Generation System

**Objective**: Generate proper type declarations for all inferred variables

**Core Components**:

1. **Declaration Formatter**
   - Generate standard Fortran declaration syntax
   - Handle different type categories (real, integer, character, logical)
   - Apply appropriate precision specifiers (real(8), etc.)

2. **Code Insertion Engine**
   - Insert declarations immediately after `implicit none`
   - Maintain proper formatting and indentation
   - Preserve existing explicit declarations (no duplication)

3. **Deduplication System**
   - Prevent duplicate declarations for already-declared variables
   - Handle mixed explicit/implicit declaration scenarios
   - Ensure declaration order consistency

### Phase 3: Integration with Code Generation

**Objective**: Seamlessly integrate automatic declarations with existing code generation pipeline

**Key Integration Points**:

1. **Semantic Analysis Pipeline**
   - Extend `semantic_analyzer_t` with declaration generation capabilities
   - Add new analysis phase between type inference and code generation
   - Maintain compatibility with existing semantic passes

2. **Code Generation Enhancement**
   - Modify `codegen_core.f90` to emit generated declarations
   - Ensure proper placement relative to `implicit none`
   - Handle function vs subroutine differences appropriately

3. **AST Enhancement**
   - Extend AST nodes to track generated declarations
   - Add metadata for distinguishing explicit vs generated declarations
   - Preserve semantic information through compilation pipeline

## Detailed Technical Specifications

### 1. Variable Discovery Algorithm

```fortran
! Enhanced semantic analyzer method
subroutine collect_undeclared_variables(this, scope_index, undeclared_vars)
    class(semantic_analyzer_t), intent(inout) :: this
    integer, intent(in) :: scope_index
    type(undeclared_variable_t), allocatable, intent(out) :: undeclared_vars(:)
```

**Process**:
1. Traverse function scope AST nodes
2. Identify all variable references (identifiers)
3. Cross-reference with explicit declarations
4. Collect undeclared variables with usage context
5. Categorize as parameters, result variables, or locals

### 2. Enhanced Type Inference

**Multi-Pass Analysis**:

1. **First Pass**: Collect all variable usages and operations
2. **Second Pass**: Apply type constraints from expressions
3. **Third Pass**: Resolve remaining ambiguities with defaults
4. **Fourth Pass**: Validate type consistency

**Type Constraint Sources**:
- Literal assignments: `x = 5.0` â†’ `x` is real
- Operation contexts: `x + y` â†’ both numeric
- Function calls: `sin(x)` â†’ `x` is real
- Array operations: `x(i)` â†’ `x` is array
- Character operations: `x // "text"` â†’ `x` is character

### 3. Intent Inference System

**Intent Determination Logic**:

```fortran
type :: usage_pattern_t
    logical :: is_read    ! Variable read in expressions
    logical :: is_written ! Variable assigned values
    logical :: is_array   ! Used with array subscripts
    logical :: is_passed  ! Passed to other functions
end type
```

**Intent Assignment Rules**:
- `intent(in)`: Only read, never written
- `intent(out)`: Only written, never read before assignment
- `intent(inout)`: Both read and written
- No intent: Local variables and result variables

### 4. Declaration Generation Format

**Output Format Standards**:

```fortran
! Integer variables
integer :: count, index, total

! Real variables with precision
real(8) :: x, y, result_value

! Character variables
character(len=*) :: input_string
character(len=:), allocatable :: dynamic_string

! Logical variables
logical :: is_valid, found

! Arrays (when detectable)
real(8) :: matrix(:,:)
integer :: indices(:)
```

**Special Cases**:
- **Function result**: No intent, may need specific type
- **Character parameters**: Use `character(len=*)` for assumed length
- **Array parameters**: Use assumed-shape `(:)` when possible
- **Optional parameters**: Preserve optional attribute if detectable

## Implementation Plan

### Step 1: Semantic Analyzer Extension (2 hours)

**Core Infrastructure**:
1. Add `collect_undeclared_variables()` method to `semantic_analyzer_t`
2. Implement `undeclared_variable_t` data structure
3. Create variable usage tracking system
4. Integrate with existing scope management

**Key Files**:
- `src/semantic/semantic_analyzer.f90` - Main implementation
- `src/semantic/scope_manager.f90` - Variable tracking support

### Step 2: Type Inference Enhancement (2.5 hours)

**Enhanced Analysis**:
1. Extend `infer_function()` with variable collection
2. Implement constraint-based type inference
3. Add intent analysis based on usage patterns
4. Create type defaulting system for unresolved variables

**Key Features**:
- Bidirectional type propagation
- Context-aware inference from operations
- Robust handling of ambiguous cases
- Integration with Hindley-Milner system

### Step 3: Declaration Generation (1.5 hours)

**Code Generation**:
1. Implement `generate_variable_declarations()` method
2. Create declaration formatting utilities
3. Add insertion logic for placing declarations
4. Implement deduplication system

**Output Quality**:
- Consistent formatting and style
- Proper type precision specifications
- Correct intent attribute assignment
- Clean integration with existing code

### Step 4: Code Generation Integration (1 hour)

**Pipeline Integration**:
1. Modify `codegen_core.f90` for declaration emission
2. Update function generation to include declarations
3. Ensure proper placement after `implicit none`
4. Handle mixed explicit/generated declarations

**Compatibility**:
- Zero breaking changes to existing functionality
- Backward compatibility with explicit declarations
- Proper error handling for edge cases

### Step 5: Comprehensive Testing (1 hour)

**Test Coverage**:
1. Simple variable declarations
2. Multiple variable types
3. Intent inference validation
4. Complex expression analysis
5. Edge cases and error conditions
6. Integration with existing test suite

**Test Categories**:
- Unit tests for each component
- Integration tests for full pipeline
- Regression tests for existing functionality
- Performance tests for large functions

## Risk Assessment and Mitigation

### High Risk: Type Inference Accuracy

**Risk**: Incorrect type inference leading to compilation errors
**Mitigation**:
- Conservative defaults when ambiguous
- Comprehensive test coverage for common patterns
- Fallback to explicit error messages for unresolvable cases
- Integration with existing type system validation

### Medium Risk: Performance Impact

**Risk**: Additional analysis passes affecting compilation speed
**Mitigation**:
- Optimize variable collection algorithms
- Cache inference results
- Only analyze functions with undeclared variables
- Profile and benchmark against existing performance

### Low Risk: Code Generation Quality

**Risk**: Generated declarations don't match user expectations
**Mitigation**:
- Follow established Fortran style conventions
- Consistent formatting with existing code
- User documentation explaining generation rules
- Option to view generated declarations in debug mode

## Success Criteria

### Functional Requirements

1. **âœ… Automatic Variable Detection**: Successfully identify all undeclared variables in functions
2. **âœ… Accurate Type Inference**: Infer correct types based on usage patterns and context
3. **âœ… Proper Intent Assignment**: Generate appropriate intent attributes for parameters
4. **âœ… Clean Declaration Generation**: Produce well-formatted, standard-compliant declarations
5. **âœ… Pipeline Integration**: Seamless integration with existing compilation pipeline

### Quality Requirements

1. **âœ… Zero Regressions**: All existing tests continue to pass
2. **âœ… Performance Maintained**: No significant impact on compilation speed
3. **âœ… Code Quality**: Generated code follows project style standards
4. **âœ… Error Handling**: Graceful handling of edge cases and ambiguous scenarios
5. **âœ… Documentation**: Clear documentation of behavior and limitations

### Validation Requirements

1. **âœ… Comprehensive Testing**: Full test coverage for all scenarios
2. **âœ… Integration Testing**: Validated with real-world Fortran code patterns
3. **âœ… Backward Compatibility**: Existing explicit declarations preserved
4. **âœ… Standard Compliance**: Generated code compiles with standard Fortran compilers
5. **âœ… User Acceptance**: Meets expectations from Issue #320 requirements

## Usage Examples

### Simple Function

```fortran
! Input
function twice(x) result(y)
    y = 2*x
end function

! Generated Output
function twice(x) result(y)
    implicit none
    real(8), intent(in) :: x
    real(8) :: y
    y = 2*x
end function twice
```

### Complex Function with Multiple Variables

```fortran
! Input
function calculate(a, b) result(result_val)
    temp = a + b
    result_val = temp * 2.0
    count = 1
end function

! Generated Output
function calculate(a, b) result(result_val)
    implicit none
    real(8), intent(in) :: a
    real(8), intent(in) :: b
    real(8) :: result_val
    real(8) :: temp
    integer :: count
    
    temp = a + b
    result_val = temp * 2.0
    count = 1
end function calculate
```

### Mixed Explicit/Implicit Declarations

```fortran
! Input (partial explicit declarations)
function process(input) result(output)
    integer :: counter
    output = input + counter + temp
    temp = 5.0
end function

! Generated Output (respects explicit declarations)
function process(input) result(output)
    implicit none
    real(8), intent(in) :: input
    real(8) :: output
    integer :: counter
    real(8) :: temp
    
    output = input + counter + temp
    temp = 5.0
end function process
```

## Integration with fortfront Ecosystem

### Lazy Fortran Support
- **Primary Goal**: Enable lazy Fortran syntax by automatically generating missing declarations
- **User Benefit**: Write concise functions without explicit type declarations
- **Standard Compliance**: Output always generates valid, standard Fortran

### Standardizer Integration
- **Seamless Integration**: Works within existing standardization pipeline
- **Quality Preservation**: Maintains fortfront's high code quality standards
- **Performance**: Optimized for standardizer's batch processing requirements

### Tool Ecosystem Support
- **fortrun Integration**: Support for module discovery and dependency analysis
- **fluff Integration**: Enhanced static analysis with complete type information
- **ffc Integration**: Proper type information for LLVM backend compilation

## Future Enhancements

### Advanced Type Inference
- **Polymorphic Types**: Support for parameterized derived types
- **Generic Interfaces**: Enhanced inference for overloaded procedures
- **Module Integration**: Cross-module type inference capabilities

### User Customization
- **Type Preferences**: User-configurable default types (real vs real(8))
- **Style Options**: Customizable declaration formatting preferences
- **Intent Policies**: Configurable intent inference strategies

### Performance Optimization
- **Incremental Analysis**: Only re-analyze changed functions
- **Parallel Processing**: Multi-threaded type inference for large codebases
- **Caching System**: Persistent type inference results